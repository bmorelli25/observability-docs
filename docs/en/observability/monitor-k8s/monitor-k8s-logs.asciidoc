[discrete]
[[monitor-kubernetes-logs]]
== Part 1: Monitor logs

[Author: @ChrsMark]

Collecting and analyzing logs of both Kubernetes Core components and various
applications running on top of Kubernetes is a powerful tool for Kubernetes
observability. Containers running within Kubernetes Pods produce logs as stdout
or stderr. These logs are written to a location known to Kubelet.

To collect Pod logs, all you need is {filebeat} running as a DaemonSet
in your Kubernetes cluster. You configure {filebeat} to communicate with the
Kubernetes API server, get the list of Pods running on the current host, and
collect the logs the Pods are producing. Those logs are annotated with all the
relevant Kubernetes metadata, such as Pod ID, container name, container labels
and annotations, and so on.

[discrete]
=== Deploy {filebeat} to collect logs

To start collecting logs, deploy and run an instance of {filebeat} on each
Kubernetes host. {filebeat} communicates with the Kubernetes API server to
retrieve information about the Pods running on the host, all the metadata
annotations, and the location of the log files.

To deploy {filebeat} to your Kubernetes cluster:

. **Download the {filebeat} deployment manifest.**
+
["source", "sh", subs="attributes"]
------------------------------------------------
curl -L -O https://raw.githubusercontent.com/elastic/beats/{branch}/deploy/kubernetes/filebeat-kubernetes.yaml
------------------------------------------------

. **Set the connection information for {es}.**
+
By default, {filebeat} sends events to an existing {es} deployment, if present.
To specify a different destination, change the following parameters in the
manifest file:
+
[source,yaml]
------------------------------------------------
- name: ELASTICSEARCH_HOST
  value: elasticsearch
- name: ELASTICSEARCH_PORT
  value: "9200"
- name: ELASTICSEARCH_USERNAME
  value: elastic
- name: ELASTICSEARCH_PASSWORD
  value: changeme
------------------------------------------------
+
Those settings can be consumed by a Kubernetes secret. To
create a secret:
+
["source", "sh", subs="attributes"]
------------------------------------------------
$ echo -n 'changeme' | base64
Y2hhbmdlbWU=
$ kubectl create secret generic es-secret --from-literal='password=Y2hhbmdlbWU='
------------------------------------------------
+
Use the secret value in {filebeat}'s env:
+
[source,yaml]
------------------------------------------------
env:
    - name: ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: es-secret
          key: password
------------------------------------------------

. **Configure log collection.**
+
To collect container logs, each {filebeat} instance needs access to the local
log's path, which is actually a log directory mounted from the host:
+
[source,yaml]
------------------------------------------------
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
------------------------------------------------
+
With this configuration {filebeat} can collect logs from all the files that
exist under the `/var/log/containers/` directory.

. *Add metadata to events.*
+
Collecting logs from containers is good, however, adding metadata to these logs
is really powerful. {filebeat} provides processors that you can use in your
configuration to enrich events with metadata coming from Docker, Kubernetes,
hosts, and cloud providers.
+
To add Kubernetes and container-related metadata to the logs, add the 
`add_kubernetes_metadata` processor to the configuration:
+
[source,yaml]
------------------------------------------------
filebeat.inputs:
- type: container
  paths:
    - /var/log/containers/*.log
  processors:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"
------------------------------------------------

. *Collect container logs through autodiscovery.*
+
Earlier you learned how to collect container logs and enrich them with metadata.
However you can take it further by leveraging the autodiscovery mechanism in
{filebeat}. With autodiscovery, {filebeat} can automatically discover what kind
of components are running in a Pod and apply the logging modules needed to
capture logs for those components.
+
To configure autodiscovery, you use static templates. For example, the template
in this example configures {filebeat} to collect Nginx logs from any Pod
labeled as `nginx`.
+
[source,yaml]
------------------------------------------------
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      templates:
        - condition:
            equals:
              kubernetes.labels.app: "nginx"
          config:
            - module: nginx
              fileset.stdout: access
              fileset.sterr: error
------------------------------------------------
+
This is good, but requires advanced knowledge of the workloads running in
Kubernetes. Each time you want to monitor something new, you'll need to
re-configure and restart {filebeat}. To avoid this, you can use hints-based
autodiscovery:
+
[source,yaml]
------------------------------------------------
filebeat.autodiscover:
  providers:
    - type: kubernetes
      node: ${NODE_NAME}
      hints.enabled: true
      hints.default_config:
        type: container
        paths:
          - /var/log/containers/*${data.kubernetes.container.id}.log
------------------------------------------------
+
Then annotate the Pods accordingly:
+
[source,yaml]
------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: nginx-autodiscover
  annotations:
    co.elastic.logs/module: nginx
    co.elastic.logs/fileset.stdout: access
    co.elastic.logs/fileset.stderr: error
------------------------------------------------
+
With this setup, {filebeat} identifies the nginx app and starts collecting its
logs by using nginx module.

. *(optional) Drop unwanted events.*
+
You can enrich your configuration with additional processors to drop unwanted
events. For example:
+
[source,yaml]
------------------------------------------------
processors:
- drop_event:
      when:
        - equals:
              kubernetes.container.name: "metricbeat"
------------------------------------------------

. *Enrich events with cloud metadata and host metadata.*
+
You can also enrich events with cloud and host metadata by specifying these
processors:
+
[source,yaml]
------------------------------------------------
processors:
- add_cloud_metadata:
- add_host_metadata:
------------------------------------------------

. *Deploy {filebeat} as a DaemonSet on Kubernetes.*
+
.. If you're running {filebeat} on master nodes, check to see if the nodes use
https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/[taints].
Taints limit the workloads that can run on master nodes. If necessary, update
the DaemonSet spec to include tolerations:
+
[source,yaml]
------------------------------------------------
spec:
 tolerations:
 - key: node-role.kubernetes.io/master
   effect: NoSchedule
------------------------------------------------

.. Deploy {filebeat} to Kubernetes:
+
["source", "sh", subs="attributes"]
------------------------------------------------
kubectl create -f filebeat-kubernetes.yaml
------------------------------------------------
+
To check the status, run:
+
["source", "sh", subs="attributes"]
------------------------------------------------
$ kubectl --namespace=kube-system get ds/filebeat

NAME       DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE-SELECTOR   AGE
filebeat   32        32        0         32           0           <none>          1m
------------------------------------------------
+
Log events should start flowing to {es}.

[discrete]
==== Red Hat OpenShift configuration

If you're using Red Hat OpenShift, you need to specify additional settings in
the manifest file and enable the container to run as privileged.

. Modify the `DaemonSet` container spec in the manifest file:
+
[source,yaml]
-----
  securityContext:
    runAsUser: 0
    privileged: true
-----

. Grant the `filebeat` service account access to the privileged SCC:
+
[source,shell]
-----
oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:filebeat
-----
+
This command enables the container to be privileged as an administrator for
OpenShift.

. Override the default node selector for the `kube-system` namespace (or your
custom namespace) to allow for scheduling on any node:
+
[source,shell]
----
oc patch namespace kube-system -p \
'{"metadata": {"annotations": {"openshift.io/node-selector": ""}}}'
----
+
This command sets the node selector for the project to an empty string. If you
don't run this command, the default node selector will skip master nodes.


[discrete]
=== View logs in {kib}

//TODO: It would be good to add a realistic scenario to talk through and
//highlight a specific use cases.

The https://www.elastic.co/log-monitoring[Logs app] in {kib} allows you to
search, filter and tail all the logs collected into the {stack}. Instead of
having to ssh into different servers and tail individual files, all the logs are
available in one tool under the Logs app.

* Check out filtering logs using the keyword or plain text search.
* You can move back and forth in time using the time picker or the timeline
view on the side.
* If you just want to watch the logs update in front of you tail -f style, click
the Streaming button and use highlighting to accentuate that important bit of
the info you are waiting to see.

//TODO: Add screenshot here

[discrete]
==== Out-of-the-box {kib} visualisations

If you've run the {filebeat} setup job, it creates a set of out-of-the-box
dashboards in {kib}.

//TODO: Add more info about the setup required. We should probably just document
//the command here.

Assuming you've deployed the sample petclinic application and it's running,
you can navigate to the {filebeat} dashboards for MySQL and NGINX.

//TODO: Add screen capture here

Notice that modules capture more than logs. You can also use them to capture
metrics. 
